{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8vOONthL1ia",
        "outputId": "9b506dc3-899a-494d-b4cf-d9a9b259991b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU Available: []\n",
            "Requirement already satisfied: librosa in c:\\users\\arnav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.11.0)\n",
            "Collecting tensorflow\n",
            "  Using cached tensorflow-2.20.0-cp311-cp311-win_amd64.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: matplotlib in c:\\users\\arnav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.9.2)\n",
            "Requirement already satisfied: seaborn in c:\\users\\arnav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.13.2)\n",
            "Requirement already satisfied: scikit-learn in c:\\users\\arnav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.5.2)\n",
            "Requirement already satisfied: audioread>=2.1.9 in c:\\users\\arnav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numba>=0.51.0 in c:\\users\\arnav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from librosa) (0.62.1)\n",
            "Requirement already satisfied: numpy>=1.22.3 in c:\\users\\arnav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from librosa) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\arnav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from librosa) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.0 in c:\\users\\arnav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from librosa) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\arnav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from librosa) (5.1.1)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in c:\\users\\arnav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from librosa) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in c:\\users\\arnav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in c:\\users\\arnav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from librosa) (1.0.0)\n",
            "Requirement already satisfied: typing_extensions>=4.1.1 in c:\\users\\arnav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from librosa) (4.12.2)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in c:\\users\\arnav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in c:\\users\\arnav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from librosa) (1.1.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\arnav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (2.3.1)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\arnav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\arnav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (25.9.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\arnav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google_pasta>=0.1.1 in c:\\users\\arnav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\arnav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt_einsum>=2.3.2 in c:\\users\\arnav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in c:\\users\\arnav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (23.1)\n",
            "Requirement already satisfied: protobuf>=5.28.0 in c:\\users\\arnav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (6.32.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\arnav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (2.31.0)\n",
            "Requirement already satisfied: setuptools in c:\\users\\arnav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (65.5.0)\n",
            "Requirement already satisfied: six>=1.12.0 in c:\\users\\arnav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\arnav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\arnav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (1.17.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\arnav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (1.75.1)\n",
            "Requirement already satisfied: tensorboard~=2.20.0 in c:\\users\\arnav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (2.20.0)\n",
            "Requirement already satisfied: keras>=3.10.0 in c:\\users\\arnav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (3.11.3)\n",
            "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\arnav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (3.14.0)\n",
            "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in c:\\users\\arnav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\arnav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\arnav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\arnav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\arnav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.8.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\arnav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.9)\n",
            "Requirement already satisfied: pillow in c:\\users\\arnav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (11.0.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\arnav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\arnav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\arnav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\arnav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\arnav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\arnav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\arnav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\arnav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: pandas>=1.2 in c:\\users\\arnav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from seaborn) (2.2.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\arnav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\arnav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in c:\\users\\arnav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from keras>=3.10.0->tensorflow) (14.2.0)\n",
            "Requirement already satisfied: namex in c:\\users\\arnav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from keras>=3.10.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in c:\\users\\arnav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from keras>=3.10.0->tensorflow) (0.17.0)\n",
            "Requirement already satisfied: llvmlite<0.46,>=0.45.0dev0 in c:\\users\\arnav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from numba>=0.51.0->librosa) (0.45.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\arnav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=1.2->seaborn) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\arnav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=1.2->seaborn) (2023.3)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in c:\\users\\arnav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pooch>=1.1->librosa) (3.10.0)\n",
            "Requirement already satisfied: cffi>=1.0 in c:\\users\\arnav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from soundfile>=0.12.1->librosa) (1.15.1)\n",
            "Requirement already satisfied: pycparser in c:\\users\\arnav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\arnav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\arnav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\arnav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in c:\\users\\arnav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.2)\n",
            "Using cached tensorflow-2.20.0-cp311-cp311-win_amd64.whl (331.8 MB)\n",
            "Installing collected packages: tensorflow\n",
            "Environment setup complete!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\\\Users\\\\arnav\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\tensorflow\\\\compiler\\\\mlir\\\\lite\\\\python\\\\_pywrap_converter_api.pyd'\n",
            "Consider using the `--user` option or check the permissions.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# STEP 1: ENVIRONMENT SETUP\n",
        "\n",
        "import tensorflow as tf\n",
        "print(\"GPU Available:\", tf.config.list_physical_devices('GPU'))\n",
        "\n",
        "!pip install librosa tensorflow matplotlib seaborn scikit-learn\n",
        "\n",
        "import os\n",
        "import pathlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import librosa\n",
        "from tensorflow.keras import layers, models\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "seed = 42\n",
        "tf.random.set_seed(seed)\n",
        "np.random.seed(seed)\n",
        "\n",
        "print(\"Environment setup complete!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JispeGndMEMp",
        "outputId": "cb090856-b244-4db5-f718-4c52904bb15f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Dataset already exists!\n",
            "\n",
            "Available Commands: ['down' 'go' 'left' 'no' 'right' 'stop' 'up' 'yes']\n",
            "down: 1000 files\n",
            "go: 1000 files\n",
            "left: 1000 files\n",
            "no: 1000 files\n",
            "right: 1000 files\n",
            "stop: 1000 files\n",
            "up: 1000 files\n",
            "yes: 1000 files\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Local dataset directory (auto-create if missing)\n",
        "DATASET_PATH = os.path.join(os.getcwd(), \"data\", \"mini_speech_commands\")\n",
        "data_dir = pathlib.Path(DATASET_PATH)\n",
        "\n",
        "# Download if not present\n",
        "if not data_dir.exists():\n",
        "    zip_path = tf.keras.utils.get_file(\n",
        "        'mini_speech_commands.zip',\n",
        "        origin=\"http://storage.googleapis.com/download.tensorflow.org/data/mini_speech_commands.zip\",\n",
        "        extract=True,\n",
        "        cache_dir='.',  # Current directory\n",
        "        cache_subdir='data'\n",
        "    )\n",
        "    print(\"✅ Dataset downloaded and extracted!\")\n",
        "\n",
        "else:\n",
        "    print(\"✅ Dataset already exists!\")\n",
        "\n",
        "# List available commands\n",
        "commands = np.array(tf.io.gfile.listdir(str(data_dir)))\n",
        "commands = commands[(commands != 'README.md') & (commands != '.DS_Store')]\n",
        "print('\\nAvailable Commands:', commands)\n",
        "\n",
        "# Show file counts\n",
        "for command in commands:\n",
        "    command_dir = data_dir / command\n",
        "    if command_dir.is_dir():\n",
        "        num_files = len(list(command_dir.glob('*.wav')))\n",
        "        print(f'{command}: {num_files} files')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9ncHNWAMoz9",
        "outputId": "2535491d-599c-44a0-badc-fc6ade4a6756"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting data preprocessing...\n",
            "Processing commands: ['down', 'go', 'left', 'no', 'right', 'stop', 'up', 'yes']\n",
            "Processing down: 1000 files\n",
            "Processing go: 1000 files\n",
            "Processing left: 1000 files\n",
            "Processing no: 1000 files\n",
            "Processing right: 1000 files\n",
            "Processing stop: 1000 files\n",
            "Processing up: 1000 files\n",
            "Processing yes: 1000 files\n",
            "Dataset shape: (4000, 98, 40)\n",
            "Labels shape: (4000,)\n",
            "Training set: (2800, 98, 40)\n",
            "Validation set: (400, 98, 40)\n",
            "Test set: (800, 98, 40)\n",
            "Class names: ['down', 'go', 'left', 'no', 'right', 'stop', 'up', 'yes']\n"
          ]
        }
      ],
      "source": [
        "# STEP 3: DATA PREPROCESSING AND FEATURE EXTRACTION\n",
        "\n",
        "def extract_mfcc_features(file_path, n_mfcc=40, max_len=98):\n",
        "    try:\n",
        "        audio, sr = librosa.load(file_path, sr=16000, duration=1.0)\n",
        "        mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=n_mfcc, hop_length=160, n_fft=512)\n",
        "        if mfccs.shape[1] < max_len:\n",
        "            mfccs = np.pad(mfccs, ((0, 0), (0, max_len - mfccs.shape[1])), mode='constant')\n",
        "        else:\n",
        "            mfccs = mfccs[:, :max_len]\n",
        "        return mfccs.T\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def prepare_dataset(data_dir, test_size=0.2, validation_size=0.1):\n",
        "    features, labels, file_paths = [], [], []\n",
        "    commands = [d for d in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, d))]\n",
        "    print(f\"Processing commands: {commands}\")\n",
        "    for label, command in enumerate(commands):\n",
        "        command_dir = os.path.join(data_dir, command)\n",
        "        audio_files = [f for f in os.listdir(command_dir) if f.endswith('.wav')]\n",
        "        print(f\"Processing {command}: {len(audio_files)} files\")\n",
        "        for audio_file in audio_files[:500]:\n",
        "            file_path = os.path.join(command_dir, audio_file)\n",
        "            mfcc_features = extract_mfcc_features(file_path)\n",
        "            if mfcc_features is not None:\n",
        "                features.append(mfcc_features)\n",
        "                labels.append(label)\n",
        "                file_paths.append(file_path)\n",
        "    features = np.array(features)\n",
        "    labels = np.array(labels)\n",
        "    print(f\"Dataset shape: {features.shape}\")\n",
        "    print(f\"Labels shape: {labels.shape}\")\n",
        "    X_temp, X_test, y_temp, y_test = train_test_split(features, labels, test_size=test_size, random_state=42, stratify=labels)\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=validation_size/(1-test_size), random_state=42, stratify=y_temp)\n",
        "    return (X_train, X_val, X_test, y_train, y_val, y_test), commands\n",
        "\n",
        "print(\"Starting data preprocessing...\")\n",
        "(X_train, X_val, X_test, y_train, y_val, y_test), class_names = prepare_dataset(data_dir)\n",
        "print(f\"Training set: {X_train.shape}\")\n",
        "print(f\"Validation set: {X_val.shape}\")\n",
        "print(f\"Test set: {X_test.shape}\")\n",
        "print(f\"Class names: {class_names}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 498
        },
        "id": "k5M4FGfjMvSG",
        "outputId": "24a678bb-0cbe-4e80-d073-b7d6a2457bd8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">98</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">79</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,304</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ pool1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">39</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">39</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │       <span style=\"color: #00af00; text-decoration-color: #00af00\">327,808</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ pool2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1920</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">245,888</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,032</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ reshape (\u001b[38;5;33mReshape\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m98\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1 (\u001b[38;5;33mConv2D\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m79\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m10,304\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ pool1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m39\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout1 (\u001b[38;5;33mDropout\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m39\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2 (\u001b[38;5;33mConv2D\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │       \u001b[38;5;34m327,808\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ pool2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout2 (\u001b[38;5;33mDropout\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1920\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense1 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m245,888\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout3 (\u001b[38;5;33mDropout\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ output (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │         \u001b[38;5;34m1,032\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">585,032</span> (2.23 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m585,032\u001b[0m (2.23 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">585,032</span> (2.23 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m585,032\u001b[0m (2.23 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CNN model architecture created.\n"
          ]
        }
      ],
      "source": [
        "# STEP 4: MODEL ARCHITECTURE DESIGN\n",
        "\n",
        "def create_cnn_model(input_shape, num_classes):\n",
        "    model = models.Sequential([\n",
        "        layers.Reshape((*input_shape, 1), input_shape=input_shape),\n",
        "        layers.Conv2D(64, (20, 8), strides=(1, 3), activation='relu', name='conv1'),\n",
        "        layers.MaxPooling2D((2, 2), name='pool1'),\n",
        "        layers.Dropout(0.25, name='dropout1'),\n",
        "        layers.Conv2D(128, (10, 4), strides=(1, 1), activation='relu', name='conv2'),\n",
        "        layers.MaxPooling2D((2, 2), name='pool2'),\n",
        "        layers.Dropout(0.25, name='dropout2'),\n",
        "        layers.Flatten(name='flatten'),\n",
        "        layers.Dense(128, activation='relu', name='dense1'),\n",
        "        layers.Dropout(0.5, name='dropout3'),\n",
        "        layers.Dense(num_classes, activation='softmax', name='output')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "input_shape = (98, 40)\n",
        "num_classes = len(class_names)\n",
        "\n",
        "cnn_model = create_cnn_model(input_shape, num_classes)\n",
        "cnn_model.summary()\n",
        "print(\"CNN model architecture created.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZtMPNB74MvVF",
        "outputId": "a6c76c16-8d33-4507-b865-9d1466d8f215"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "44/44 - 9s - 202ms/step - accuracy: 0.1368 - loss: 3.9496 - val_accuracy: 0.1425 - val_loss: 2.0720 - learning_rate: 0.0010\n",
            "Epoch 2/30\n",
            "44/44 - 6s - 130ms/step - accuracy: 0.1389 - loss: 2.0789 - val_accuracy: 0.1125 - val_loss: 2.0786 - learning_rate: 0.0010\n",
            "Epoch 3/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "44/44 - 6s - 136ms/step - accuracy: 0.1282 - loss: 2.0766 - val_accuracy: 0.1500 - val_loss: 2.0696 - learning_rate: 0.0010\n",
            "Epoch 4/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "44/44 - 6s - 132ms/step - accuracy: 0.1475 - loss: 2.0674 - val_accuracy: 0.1875 - val_loss: 2.0412 - learning_rate: 0.0010\n",
            "Epoch 5/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "44/44 - 5s - 122ms/step - accuracy: 0.1621 - loss: 2.0144 - val_accuracy: 0.2575 - val_loss: 1.9299 - learning_rate: 0.0010\n",
            "Epoch 6/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "44/44 - 5s - 123ms/step - accuracy: 0.2029 - loss: 1.9707 - val_accuracy: 0.2750 - val_loss: 1.8384 - learning_rate: 0.0010\n",
            "Epoch 7/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "44/44 - 6s - 128ms/step - accuracy: 0.2629 - loss: 1.9072 - val_accuracy: 0.3425 - val_loss: 1.7398 - learning_rate: 0.0010\n",
            "Epoch 8/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "44/44 - 6s - 133ms/step - accuracy: 0.2857 - loss: 1.8568 - val_accuracy: 0.3750 - val_loss: 1.6700 - learning_rate: 0.0010\n",
            "Epoch 9/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "44/44 - 6s - 133ms/step - accuracy: 0.3146 - loss: 1.7507 - val_accuracy: 0.3950 - val_loss: 1.5161 - learning_rate: 0.0010\n",
            "Epoch 10/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "44/44 - 6s - 126ms/step - accuracy: 0.3879 - loss: 1.5926 - val_accuracy: 0.4975 - val_loss: 1.3895 - learning_rate: 0.0010\n",
            "Epoch 11/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "44/44 - 5s - 121ms/step - accuracy: 0.4339 - loss: 1.5034 - val_accuracy: 0.5425 - val_loss: 1.2159 - learning_rate: 0.0010\n",
            "Epoch 12/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "44/44 - 5s - 121ms/step - accuracy: 0.4714 - loss: 1.3945 - val_accuracy: 0.6175 - val_loss: 1.0468 - learning_rate: 0.0010\n",
            "Epoch 13/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "44/44 - 6s - 127ms/step - accuracy: 0.5611 - loss: 1.1813 - val_accuracy: 0.6525 - val_loss: 0.9289 - learning_rate: 0.0010\n",
            "Epoch 14/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "44/44 - 6s - 132ms/step - accuracy: 0.6121 - loss: 1.0280 - val_accuracy: 0.6625 - val_loss: 0.8585 - learning_rate: 0.0010\n",
            "Epoch 15/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "44/44 - 6s - 132ms/step - accuracy: 0.6321 - loss: 1.0182 - val_accuracy: 0.7450 - val_loss: 0.7189 - learning_rate: 0.0010\n",
            "Epoch 16/30\n",
            "44/44 - 5s - 117ms/step - accuracy: 0.6668 - loss: 0.8934 - val_accuracy: 0.7450 - val_loss: 0.7910 - learning_rate: 0.0010\n",
            "Epoch 17/30\n",
            "44/44 - 5s - 121ms/step - accuracy: 0.7171 - loss: 0.7796 - val_accuracy: 0.7400 - val_loss: 0.7477 - learning_rate: 0.0010\n",
            "Epoch 18/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "44/44 - 6s - 126ms/step - accuracy: 0.7246 - loss: 0.7617 - val_accuracy: 0.7475 - val_loss: 0.7526 - learning_rate: 0.0010\n",
            "Epoch 19/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "44/44 - 6s - 131ms/step - accuracy: 0.7257 - loss: 0.7620 - val_accuracy: 0.7775 - val_loss: 0.6392 - learning_rate: 0.0010\n",
            "Epoch 20/30\n",
            "44/44 - 6s - 131ms/step - accuracy: 0.7450 - loss: 0.7254 - val_accuracy: 0.7775 - val_loss: 0.6818 - learning_rate: 0.0010\n",
            "Epoch 21/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "44/44 - 5s - 121ms/step - accuracy: 0.7732 - loss: 0.6263 - val_accuracy: 0.7875 - val_loss: 0.5812 - learning_rate: 0.0010\n",
            "Epoch 22/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "44/44 - 5s - 119ms/step - accuracy: 0.7850 - loss: 0.6277 - val_accuracy: 0.7975 - val_loss: 0.5634 - learning_rate: 0.0010\n",
            "Epoch 23/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "44/44 - 5s - 120ms/step - accuracy: 0.8043 - loss: 0.5681 - val_accuracy: 0.8150 - val_loss: 0.5804 - learning_rate: 0.0010\n",
            "Epoch 24/30\n",
            "44/44 - 5s - 122ms/step - accuracy: 0.8157 - loss: 0.5513 - val_accuracy: 0.8050 - val_loss: 0.6493 - learning_rate: 0.0010\n",
            "Epoch 25/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "44/44 - 6s - 127ms/step - accuracy: 0.8068 - loss: 0.5419 - val_accuracy: 0.8450 - val_loss: 0.4713 - learning_rate: 0.0010\n",
            "Epoch 26/30\n",
            "44/44 - 5s - 123ms/step - accuracy: 0.8261 - loss: 0.5225 - val_accuracy: 0.8225 - val_loss: 0.5250 - learning_rate: 0.0010\n",
            "Epoch 27/30\n",
            "44/44 - 5s - 117ms/step - accuracy: 0.8275 - loss: 0.4924 - val_accuracy: 0.8050 - val_loss: 0.5857 - learning_rate: 0.0010\n",
            "Epoch 28/30\n",
            "44/44 - 6s - 130ms/step - accuracy: 0.8282 - loss: 0.4904 - val_accuracy: 0.8375 - val_loss: 0.5465 - learning_rate: 0.0010\n",
            "Epoch 29/30\n",
            "44/44 - 6s - 132ms/step - accuracy: 0.8329 - loss: 0.4970 - val_accuracy: 0.8350 - val_loss: 0.5058 - learning_rate: 0.0010\n",
            "Epoch 30/30\n",
            "44/44 - 5s - 123ms/step - accuracy: 0.8346 - loss: 0.4940 - val_accuracy: 0.8325 - val_loss: 0.5551 - learning_rate: 0.0010\n",
            "Training complete. Final epoch metrics:\n",
            "Train accuracy: 0.8346428275108337\n",
            "Validation accuracy: 0.8324999809265137\n"
          ]
        }
      ],
      "source": [
        "# STEP 5: MODEL TRAINING\n",
        "\n",
        "def train_model(model, X_train, y_train, X_val, y_val, epochs=30, batch_size=64):\n",
        "    callbacks = [\n",
        "        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "        tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-7),\n",
        "        tf.keras.callbacks.ModelCheckpoint('best_model.h5', save_best_only=True, monitor='val_accuracy')\n",
        "    ]\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    history = model.fit(X_train, y_train,\n",
        "                        validation_data=(X_val, y_val),\n",
        "                        epochs=epochs, batch_size=batch_size,\n",
        "                        callbacks=callbacks, verbose=2)\n",
        "    print(\"Training complete. Final epoch metrics:\")\n",
        "    print(\"Train accuracy:\", history.history['accuracy'][-1])\n",
        "    print(\"Validation accuracy:\", history.history['val_accuracy'][-1])\n",
        "    return history\n",
        "\n",
        "history = train_model(cnn_model, X_train, y_train, X_val, y_val)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2gi-aBXUMvYH",
        "outputId": "4b39cd4a-363a-475d-abb7-cba58ebd8593"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating the model...\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step\n",
            "Test Accuracy: 0.84375\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        down       0.86      0.81      0.84       100\n",
            "          go       0.79      0.69      0.74       100\n",
            "        left       0.84      0.86      0.85       100\n",
            "          no       0.75      0.79      0.77       100\n",
            "       right       0.94      0.93      0.93       100\n",
            "        stop       0.91      0.88      0.89       100\n",
            "          up       0.78      0.88      0.83       100\n",
            "         yes       0.88      0.91      0.90       100\n",
            "\n",
            "    accuracy                           0.84       800\n",
            "   macro avg       0.84      0.84      0.84       800\n",
            "weighted avg       0.84      0.84      0.84       800\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x800 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# STEP 6: MODEL EVALUATION\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "def evaluate_model(model, X_test, y_test, class_names):\n",
        "    predictions = model.predict(X_test)\n",
        "    predicted_classes = np.argmax(predictions, axis=1)\n",
        "    test_accuracy = np.mean(predicted_classes == y_test)\n",
        "    print(\"Test Accuracy:\", test_accuracy)\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report(y_test, predicted_classes, target_names=class_names))\n",
        "    cm = confusion_matrix(y_test, predicted_classes)\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('Actual')\n",
        "    plt.show()\n",
        "    return test_accuracy\n",
        "\n",
        "print(\"Evaluating the model...\")\n",
        "test_accuracy = evaluate_model(cnn_model, X_test, y_test, class_names)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3t5lzroMvay",
        "outputId": "52c6e17a-49ef-47b3-bcfd-bd1d6485c655"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved as speech_command_cnn_model.h5\n",
            "Running prediction on: c:\\Users\\arnav\\OneDrive\\Desktop\\data\\mini_speech_commands\\down\\004ae714_nohash_0.wav\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step\n",
            "Predicted command: down\n",
            "Confidence: 0.5360\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "('down', 0.53603756)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# STEP 7: DEPLOYMENT AND SAMPLE INFERENCE\n",
        "\n",
        "cnn_model.save('speech_command_cnn_model.h5')\n",
        "print(\"Model saved as speech_command_cnn_model.h5\")\n",
        "\n",
        "def predict_audio_command(model, audio_file_path, class_names):\n",
        "    features = extract_mfcc_features(audio_file_path)\n",
        "    if features is not None:\n",
        "        features = np.expand_dims(features, axis=0)\n",
        "        predictions = model.predict(features)\n",
        "        predicted_class_idx = np.argmax(predictions[0])\n",
        "        confidence = predictions[0][predicted_class_idx]\n",
        "        predicted_class = class_names[predicted_class_idx]\n",
        "        print(f\"Predicted command: {predicted_class}\")\n",
        "        print(f\"Confidence: {confidence:.4f}\")\n",
        "        return predicted_class, confidence\n",
        "    else:\n",
        "        print(\"Error: Could not process audio file\")\n",
        "        return None, None\n",
        "\n",
        "# Test prediction on a sample file\n",
        "sample_test_file = list((data_dir / class_names[0]).glob('*.wav'))[0]\n",
        "print(f\"Running prediction on: {sample_test_file}\")\n",
        "predict_audio_command(cnn_model, str(sample_test_file), class_names)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "leTjxTMsNNGX"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Model saved as 'speech_command_cnn_model.h5'\n",
            "\n",
            "============================================================\n",
            "TESTING PREDICTIONS ON SAMPLE FILES\n",
            "============================================================\n",
            "\n",
            "--- Test 1: Single Sample ---\n",
            "File: 004ae714_nohash_0.wav\n",
            "🎯 Predicted command: down\n",
            "📊 Confidence: 53.60%\n",
            "\n",
            "--- Test 2: One Sample Per Class ---\n",
            "\n",
            "📁 Testing 'down':\n",
            "   File: 1d919a90_nohash_0.wav\n",
            "🎯 Predicted command: down\n",
            "📊 Confidence: 86.83%\n",
            "\n",
            "📁 Testing 'go':\n",
            "   File: 721f767c_nohash_0.wav\n",
            "🎯 Predicted command: go\n",
            "📊 Confidence: 84.23%\n",
            "\n",
            "📁 Testing 'left':\n",
            "   File: dea820ce_nohash_2.wav\n",
            "🎯 Predicted command: left\n",
            "📊 Confidence: 68.42%\n",
            "\n",
            "📁 Testing 'no':\n",
            "   File: 46a153d8_nohash_4.wav\n",
            "🎯 Predicted command: no\n",
            "📊 Confidence: 88.79%\n",
            "\n",
            "📁 Testing 'right':\n",
            "   File: 21832144_nohash_3.wav\n",
            "🎯 Predicted command: right\n",
            "📊 Confidence: 99.55%\n",
            "\n",
            "📁 Testing 'stop':\n",
            "   File: 1816b768_nohash_1.wav\n",
            "🎯 Predicted command: stop\n",
            "📊 Confidence: 99.99%\n",
            "\n",
            "📁 Testing 'up':\n",
            "   File: ba59cab3_nohash_0.wav\n",
            "🎯 Predicted command: up\n",
            "📊 Confidence: 78.90%\n",
            "\n",
            "📁 Testing 'yes':\n",
            "   File: 03cf93b1_nohash_0.wav\n",
            "🎯 Predicted command: yes\n",
            "📊 Confidence: 99.96%\n",
            "\n",
            "============================================================\n",
            "BATCH PREDICTION SUMMARY\n",
            "============================================================\n",
            "🎯 Predicted command: down\n",
            "📊 Confidence: 84.90%\n",
            "🎯 Predicted command: down\n",
            "📊 Confidence: 51.41%\n",
            "🎯 Predicted command: no\n",
            "📊 Confidence: 60.44%\n",
            "🎯 Predicted command: down\n",
            "📊 Confidence: 57.69%\n",
            "🎯 Predicted command: down\n",
            "📊 Confidence: 71.79%\n",
            "🎯 Predicted command: go\n",
            "📊 Confidence: 71.01%\n",
            "🎯 Predicted command: go\n",
            "📊 Confidence: 83.29%\n",
            "🎯 Predicted command: go\n",
            "📊 Confidence: 86.98%\n",
            "🎯 Predicted command: go\n",
            "📊 Confidence: 38.23%\n",
            "🎯 Predicted command: go\n",
            "📊 Confidence: 52.57%\n",
            "🎯 Predicted command: left\n",
            "📊 Confidence: 99.90%\n",
            "🎯 Predicted command: left\n",
            "📊 Confidence: 100.00%\n",
            "🎯 Predicted command: left\n",
            "📊 Confidence: 100.00%\n",
            "🎯 Predicted command: left\n",
            "📊 Confidence: 86.49%\n",
            "🎯 Predicted command: left\n",
            "📊 Confidence: 100.00%\n",
            "🎯 Predicted command: no\n",
            "📊 Confidence: 98.48%\n",
            "🎯 Predicted command: no\n",
            "📊 Confidence: 84.39%\n",
            "🎯 Predicted command: no\n",
            "📊 Confidence: 51.59%\n",
            "🎯 Predicted command: no\n",
            "📊 Confidence: 76.79%\n",
            "🎯 Predicted command: go\n",
            "📊 Confidence: 52.36%\n",
            "🎯 Predicted command: right\n",
            "📊 Confidence: 100.00%\n",
            "🎯 Predicted command: right\n",
            "📊 Confidence: 100.00%\n",
            "🎯 Predicted command: right\n",
            "📊 Confidence: 97.48%\n",
            "🎯 Predicted command: right\n",
            "📊 Confidence: 100.00%\n",
            "🎯 Predicted command: right\n",
            "📊 Confidence: 99.99%\n",
            "🎯 Predicted command: up\n",
            "📊 Confidence: 36.97%\n",
            "🎯 Predicted command: stop\n",
            "📊 Confidence: 99.97%\n",
            "🎯 Predicted command: stop\n",
            "📊 Confidence: 100.00%\n",
            "🎯 Predicted command: stop\n",
            "📊 Confidence: 100.00%\n",
            "🎯 Predicted command: stop\n",
            "📊 Confidence: 86.50%\n",
            "🎯 Predicted command: up\n",
            "📊 Confidence: 42.24%\n",
            "🎯 Predicted command: up\n",
            "📊 Confidence: 81.95%\n",
            "🎯 Predicted command: up\n",
            "📊 Confidence: 99.24%\n",
            "🎯 Predicted command: up\n",
            "📊 Confidence: 84.18%\n",
            "🎯 Predicted command: stop\n",
            "📊 Confidence: 51.90%\n",
            "🎯 Predicted command: yes\n",
            "📊 Confidence: 99.88%\n",
            "🎯 Predicted command: yes\n",
            "📊 Confidence: 100.00%\n",
            "🎯 Predicted command: yes\n",
            "📊 Confidence: 99.99%\n",
            "🎯 Predicted command: yes\n",
            "📊 Confidence: 100.00%\n",
            "🎯 Predicted command: stop\n",
            "📊 Confidence: 63.37%\n",
            "\n",
            "✅ Batch Test Accuracy: 35/40 (87.50%)\n",
            "\n",
            "============================================================\n",
            "DEPLOYMENT READY!\n",
            "============================================================\n",
            "To use the model in production:\n",
            "1. Load model: model = tf.keras.models.load_model('speech_command_cnn_model.h5')\n",
            "2. Call: predict_audio_command(model, 'path/to/audio.wav', class_names)\n"
          ]
        }
      ],
      "source": [
        "# def predict_audio_command(model, audio_file_path, class_names):\n",
        "#     '''Predict speech command from audio file'''\n",
        "#     features = extract_mfcc_features(audio_file_path)\n",
        "\n",
        "#     if features is not None:\n",
        "#         features = np.expand_dims(features, axis=0)\n",
        "#         predictions = model.predict(features)\n",
        "#         predicted_class_idx = np.argmax(predictions[0])\n",
        "#         confidence = predictions[0][predicted_class_idx]\n",
        "#         predicted_class = class_names[predicted_class_idx]\n",
        "\n",
        "#         print(f\"Predicted command: {predicted_class}\")\n",
        "#         print(f\"Confidence: {confidence:.4f}\")\n",
        "\n",
        "#         return predicted_class, confidence\n",
        "\n",
        "#     return None, None\n",
        "\n",
        "# STEP 7: MODEL DEPLOYMENT AND INFERENCE\n",
        "\n",
        "# Save the trained model\n",
        "cnn_model.save('speech_command_cnn_model.h5')\n",
        "print(\"✓ Model saved as 'speech_command_cnn_model.h5'\\n\")\n",
        "\n",
        "def predict_audio_command(model, audio_file_path, class_names):\n",
        "    \"\"\"\n",
        "    Predict speech command from an audio file\n",
        "    \n",
        "    Args:\n",
        "        model: Trained Keras model\n",
        "        audio_file_path (str): Path to the audio file\n",
        "        class_names (list): List of command class names\n",
        "        \n",
        "    Returns:\n",
        "        tuple: (predicted_class, confidence) or (None, None) if error\n",
        "    \"\"\"\n",
        "    # Extract MFCC features from audio file\n",
        "    features = extract_mfcc_features(audio_file_path)\n",
        "    \n",
        "    if features is None:\n",
        "        print(\"❌ Error: Could not process audio file\")\n",
        "        return None, None\n",
        "    \n",
        "    # Reshape for model input (add batch dimension)\n",
        "    features = np.expand_dims(features, axis=0)\n",
        "    \n",
        "    # Make prediction\n",
        "    predictions = model.predict(features, verbose=0)\n",
        "    predicted_class_idx = np.argmax(predictions[0])\n",
        "    confidence = predictions[0][predicted_class_idx]\n",
        "    predicted_class = class_names[predicted_class_idx]\n",
        "    \n",
        "    # Display results\n",
        "    print(f\"🎯 Predicted command: {predicted_class}\")\n",
        "    print(f\"📊 Confidence: {confidence:.2%}\")\n",
        "    \n",
        "    return predicted_class, confidence\n",
        "\n",
        "# ========================================\n",
        "# TEST PREDICTIONS ON SAMPLE FILES\n",
        "# ========================================\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"TESTING PREDICTIONS ON SAMPLE FILES\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Test 1: Single sample from first class\n",
        "print(\"\\n--- Test 1: Single Sample ---\")\n",
        "sample_test_file = list((data_dir / class_names[0]).glob('*.wav'))[0]\n",
        "print(f\"File: {sample_test_file.name}\")\n",
        "predict_audio_command(cnn_model, str(sample_test_file), class_names)\n",
        "\n",
        "# Test 2: Random sample from each class\n",
        "print(\"\\n--- Test 2: One Sample Per Class ---\")\n",
        "np.random.seed(42)\n",
        "for class_name in class_names:\n",
        "    audio_files = list((data_dir / class_name).glob('*.wav'))\n",
        "    if audio_files:\n",
        "        sample_file = np.random.choice(audio_files)\n",
        "        print(f\"\\n📁 Testing '{class_name}':\")\n",
        "        print(f\"   File: {sample_file.name}\")\n",
        "        predict_audio_command(cnn_model, str(sample_file), class_names)\n",
        "\n",
        "# Test 3: Prediction on multiple samples with summary\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"BATCH PREDICTION SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "correct_predictions = 0\n",
        "total_predictions = 0\n",
        "\n",
        "for class_name in class_names:\n",
        "    audio_files = list((data_dir / class_name).glob('*.wav'))\n",
        "    # Test 5 random samples per class\n",
        "    test_samples = np.random.choice(audio_files, min(5, len(audio_files)), replace=False)\n",
        "    \n",
        "    for sample_file in test_samples:\n",
        "        predicted, conf = predict_audio_command(cnn_model, str(sample_file), class_names)\n",
        "        if predicted == class_name:\n",
        "            correct_predictions += 1\n",
        "        total_predictions += 1\n",
        "\n",
        "accuracy = (correct_predictions / total_predictions) * 100\n",
        "print(f\"\\n✅ Batch Test Accuracy: {correct_predictions}/{total_predictions} ({accuracy:.2f}%)\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"DEPLOYMENT READY!\")\n",
        "print(\"=\"*60)\n",
        "print(\"To use the model in production:\")\n",
        "print(\"1. Load model: model = tf.keras.models.load_model('speech_command_cnn_model.h5')\")\n",
        "print(\"2. Call: predict_audio_command(model, 'path/to/audio.wav', class_names)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "fyQl5qKnMvdM"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Model saved as 'speech_command_cnn_model.keras'\n",
            "\n",
            "============================================================\n",
            "TESTING PREDICTIONS ON SAMPLE FILES\n",
            "============================================================\n",
            "\n",
            "--- Test 1: Single Sample ---\n",
            "File: 004ae714_nohash_0.wav\n",
            "🎯 Predicted: down | Confidence: 53.60%\n",
            "\n",
            "--- Test 2: One Sample Per Class ---\n",
            "✓ True: down   | Predicted: down   | Confidence: 86.83%\n",
            "✓ True: go     | Predicted: go     | Confidence: 84.23%\n",
            "✓ True: left   | Predicted: left   | Confidence: 68.42%\n",
            "✓ True: no     | Predicted: no     | Confidence: 88.79%\n",
            "✓ True: right  | Predicted: right  | Confidence: 99.55%\n",
            "✓ True: stop   | Predicted: stop   | Confidence: 99.99%\n",
            "✓ True: up     | Predicted: up     | Confidence: 78.90%\n",
            "✓ True: yes    | Predicted: yes    | Confidence: 99.96%\n",
            "\n",
            "--- Test 3: Batch Prediction Summary ---\n",
            "  down  : 4/5 correct (80%)\n",
            "  go    : 4/5 correct (80%)\n",
            "  left  : 5/5 correct (100%)\n",
            "  no    : 4/5 correct (80%)\n",
            "  right : 5/5 correct (100%)\n",
            "  stop  : 4/5 correct (80%)\n",
            "  up    : 4/5 correct (80%)\n",
            "  yes   : 4/5 correct (80%)\n",
            "\n",
            "✅ Overall Batch Accuracy: 34/40 (85.00%)\n",
            "\n",
            "============================================================\n",
            "DEPLOYMENT READY!\n",
            "============================================================\n",
            "To use the model in production:\n",
            "  1. Load: model = tf.keras.models.load_model('speech_command_cnn_model.keras')\n",
            "  2. Use:  predict_audio_command(model, 'audio.wav', class_names)\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# STEP 7: MODEL DEPLOYMENT AND INFERENCE\n",
        "\n",
        "# Save the trained model\n",
        "cnn_model.save('speech_command_cnn_model.keras')  # Use new Keras format\n",
        "print(\"✓ Model saved as 'speech_command_cnn_model.keras'\\n\")\n",
        "\n",
        "def predict_audio_command(model, audio_file_path, class_names):\n",
        "    \"\"\"\n",
        "    Predict speech command from an audio file\n",
        "    \n",
        "    Args:\n",
        "        model: Trained Keras model\n",
        "        audio_file_path (str): Path to the audio file\n",
        "        class_names (list): List of command class names\n",
        "        \n",
        "    Returns:\n",
        "        tuple: (predicted_class, confidence) or (None, None) if error\n",
        "    \"\"\"\n",
        "    features = extract_mfcc_features(audio_file_path)\n",
        "    \n",
        "    if features is None:\n",
        "        print(\"❌ Error: Could not process audio file\")\n",
        "        return None, None\n",
        "    \n",
        "    features = np.expand_dims(features, axis=0)\n",
        "    predictions = model.predict(features, verbose=0)\n",
        "    predicted_class_idx = np.argmax(predictions[0])\n",
        "    confidence = predictions[0][predicted_class_idx]\n",
        "    predicted_class = class_names[predicted_class_idx]\n",
        "    \n",
        "    return predicted_class, confidence\n",
        "\n",
        "# ========================================\n",
        "# TEST PREDICTIONS\n",
        "# ========================================\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"TESTING PREDICTIONS ON SAMPLE FILES\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Test 1: Single sample\n",
        "print(\"\\n--- Test 1: Single Sample ---\")\n",
        "sample_test_file = list((data_dir / class_names[0]).glob('*.wav'))[0]\n",
        "print(f\"File: {sample_test_file.name}\")\n",
        "pred, conf = predict_audio_command(cnn_model, str(sample_test_file), class_names)\n",
        "print(f\"🎯 Predicted: {pred} | Confidence: {conf:.2%}\")\n",
        "\n",
        "# Test 2: One sample per class (COMPACT OUTPUT)\n",
        "print(\"\\n--- Test 2: One Sample Per Class ---\")\n",
        "np.random.seed(42)\n",
        "results = []\n",
        "for class_name in class_names:\n",
        "    audio_files = list((data_dir / class_name).glob('*.wav'))\n",
        "    if audio_files:\n",
        "        sample_file = np.random.choice(audio_files)\n",
        "        pred, conf = predict_audio_command(cnn_model, str(sample_file), class_names)\n",
        "        status = \"✓\" if pred == class_name else \"✗\"\n",
        "        results.append((class_name, pred, conf, status))\n",
        "        print(f\"{status} True: {class_name:6} | Predicted: {pred:6} | Confidence: {conf:.2%}\")\n",
        "\n",
        "# Test 3: Batch accuracy\n",
        "print(\"\\n--- Test 3: Batch Prediction Summary ---\")\n",
        "correct = 0\n",
        "total = 0\n",
        "np.random.seed(42)\n",
        "\n",
        "for class_name in class_names:\n",
        "    audio_files = list((data_dir / class_name).glob('*.wav'))\n",
        "    test_samples = np.random.choice(audio_files, min(5, len(audio_files)), replace=False)\n",
        "    \n",
        "    class_correct = 0\n",
        "    for sample_file in test_samples:\n",
        "        predicted, conf = predict_audio_command(cnn_model, str(sample_file), class_names)\n",
        "        if predicted == class_name:\n",
        "            correct += 1\n",
        "            class_correct += 1\n",
        "        total += 1\n",
        "    \n",
        "    class_acc = (class_correct / len(test_samples)) * 100\n",
        "    print(f\"  {class_name:6}: {class_correct}/{len(test_samples)} correct ({class_acc:.0f}%)\")\n",
        "\n",
        "accuracy = (correct / total) * 100\n",
        "print(f\"\\n✅ Overall Batch Accuracy: {correct}/{total} ({accuracy:.2f}%)\")\n",
        "\n",
        "# Deployment instructions\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"DEPLOYMENT READY!\")\n",
        "print(\"=\"*60)\n",
        "print(\"To use the model in production:\")\n",
        "print(\"  1. Load: model = tf.keras.models.load_model('speech_command_cnn_model.keras')\")\n",
        "print(\"  2. Use:  predict_audio_command(model, 'audio.wav', class_names)\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G8T3pEjSMvfw"
      },
      "outputs": [],
      "source": [
        "project_folder/\n",
        "│\n",
        "├── speech_command_cnn_model.keras    # 🎯 The trained model\n",
        "├── predict_audio_command.py          # 🔧 Inference function\n",
        "├── extract_mfcc_features.py          # 🎵 Audio preprocessing\n",
        "├── requirements.txt                  # 📦 Dependencies\n",
        "├── README.md                         # 📖 Documentation\n",
        "├── demo.py                           # 🎮 Example usage\n",
        "├── test_samples/                     # 🎤 Sample audio files\n",
        "│   ├── yes.wav\n",
        "│   ├── no.wav\n",
        "│   └── ...\n",
        "└── model_performance/                # 📊 Results\n",
        "    ├── confusion_matrix.png\n",
        "    ├── accuracy_plot.png\n",
        "    └── classification_report.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aXjNn1nGMviW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rVCIDfRMMvk_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XScbGlY5Mvno"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dk-cvKToMvqU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lxeLmAqUMvsz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GO7Mq9MwMvvm"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
